{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79cb518c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zstandard as zstd\n",
    "import hashlib\n",
    "import codecs\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae98f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path=\"gu_meta_part_1.jsonl.zst\"\n",
    "output_path=\"gu_meta_part_1.txt\"\n",
    "expected_sha256=\"6f0bbaabd018fa5421c4f4fb4ef281359f602ecfd06c2b2bca606f48e48e354c\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "989d93f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Checksum OK for gu_meta_part_1.jsonl.zst\n",
      "✅ Decompressed gu_meta_part_1.jsonl.zst → gu_meta_part_1.jsonl.txt\n",
      "✔ Checksum OK for gu_meta_part_3.jsonl.zst\n",
      "✅ Decompressed gu_meta_part_3.jsonl.zst → gu_meta_part_3.jsonl.txt\n",
      "✔ Checksum OK for gu_meta_part_2.jsonl.zst\n",
      "✅ Decompressed gu_meta_part_2.jsonl.zst → gu_meta_part_2.jsonl.txt\n",
      "✔ Checksum OK for gu_meta_part_4.jsonl.zst\n",
      "✅ Decompressed gu_meta_part_4.jsonl.zst → gu_meta_part_4.jsonl.txt\n"
     ]
    }
   ],
   "source": [
    "def file_sha256(file_path, chunk_size=2**20):\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        while chunk := f.read(chunk_size):\n",
    "            sha256.update(chunk)\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "def decompress_jsonl_zst(input_path, output_path=None, chunk_size=2**20):\n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".txt\"\n",
    "    \n",
    "    dctx = zstd.ZstdDecompressor()\n",
    "    decoder = codecs.getincrementaldecoder(\"utf-8\")()\n",
    "\n",
    "    with open(input_path, \"rb\") as f_in, open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        with dctx.stream_reader(f_in) as reader:\n",
    "            while True:\n",
    "                chunk = reader.read(chunk_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                f_out.write(decoder.decode(chunk))\n",
    "        f_out.write(decoder.decode(b\"\", final=True))\n",
    "    \n",
    "    print(f\"✅ Decompressed {os.path.basename(input_path)} → {os.path.basename(output_path)}\")\n",
    "\n",
    "def batch_decompress(checksum_file, folder):\n",
    "    with open(checksum_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            expected_hash, filename = parts\n",
    "            file_path = os.path.join(folder, filename)\n",
    "\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"❌ Missing file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            actual_hash = file_sha256(file_path)\n",
    "            if actual_hash.lower() != expected_hash.lower():\n",
    "                print(f\"❌ Checksum mismatch for {filename}! Skipping.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"✔ Checksum OK for {filename}\")\n",
    "            decompress_jsonl_zst(file_path)\n",
    "\n",
    "# Example usage:\n",
    "batch_decompress(\n",
    "    checksum_file=r\"D:\\collage\\NLP\\Assignment_1\\2\\checksum.sha256.txt\",\n",
    "    folder=r\"D:\\collage\\NLP\\Assignment_1\\2\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2909e09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0b77d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c572cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Checksum mismatch for gu_meta_part_3.jsonl.zst! Skipping.\n",
      "✔ Checksum OK for gu_meta_part_4.jsonl.zst\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 48\u001b[0m\n\u001b[0;32m     45\u001b[0m             decompress_jsonl_zst(file_path)\n\u001b[0;32m     47\u001b[0m \u001b[38;5;66;03m# Example usage:\u001b[39;00m\n\u001b[1;32m---> 48\u001b[0m \u001b[43mbatch_decompress\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchecksum_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcollage\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mNLP\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAssignment_1\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mchecksum2.sha256.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcollage\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mNLP\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mAssignment_1\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     51\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 45\u001b[0m, in \u001b[0;36mbatch_decompress\u001b[1;34m(checksum_file, folder)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✔ Checksum OK for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 45\u001b[0m \u001b[43mdecompress_jsonl_zst\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 21\u001b[0m, in \u001b[0;36mdecompress_jsonl_zst\u001b[1;34m(input_path, output_path, chunk_size)\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m chunk:\n\u001b[0;32m     20\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m             \u001b[43mf_out\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m     f_out\u001b[38;5;241m.\u001b[39mwrite(decoder\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Decompressed \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(input_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m → \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mos\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(output_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "\n",
    "def file_sha256(file_path, chunk_size=2**20):\n",
    "    sha256 = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        while chunk := f.read(chunk_size):\n",
    "            sha256.update(chunk)\n",
    "    return sha256.hexdigest()\n",
    "\n",
    "def decompress_jsonl_zst(input_path, output_path=None, chunk_size=2**20):\n",
    "    if output_path is None:\n",
    "        output_path = os.path.splitext(input_path)[0] + \".txt\"\n",
    "    \n",
    "    dctx = zstd.ZstdDecompressor()\n",
    "    decoder = codecs.getincrementaldecoder(\"utf-8\")()\n",
    "\n",
    "    with open(input_path, \"rb\") as f_in, open(output_path, \"w\", encoding=\"utf-8\") as f_out:\n",
    "        with dctx.stream_reader(f_in) as reader:\n",
    "            while True:\n",
    "                chunk = reader.read(chunk_size)\n",
    "                if not chunk:\n",
    "                    break\n",
    "                f_out.write(decoder.decode(chunk))\n",
    "        f_out.write(decoder.decode(b\"\", final=True))\n",
    "    \n",
    "    print(f\"✅ Decompressed {os.path.basename(input_path)} → {os.path.basename(output_path)}\")\n",
    "\n",
    "def batch_decompress(checksum_file, folder):\n",
    "    with open(checksum_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split(maxsplit=1)\n",
    "            if len(parts) != 2:\n",
    "                continue\n",
    "            expected_hash, filename = parts\n",
    "            file_path = os.path.join(folder, filename)\n",
    "\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"❌ Missing file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            actual_hash = file_sha256(file_path)\n",
    "            if actual_hash.lower() != expected_hash.lower():\n",
    "                print(f\"❌ Checksum mismatch for {filename}! Skipping.\")\n",
    "                continue\n",
    "\n",
    "            print(f\"✔ Checksum OK for {filename}\")\n",
    "            decompress_jsonl_zst(file_path)\n",
    "\n",
    "# Example usage:\n",
    "batch_decompress(\n",
    "    checksum_file=r\"D:\\collage\\NLP\\Assignment_1\\2\\checksum2.sha256.txt\",\n",
    "    folder=r\"D:\\collage\\NLP\\Assignment_1\\2\"\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
